{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MNoichl/tttms_public/blob/main/converting_biorxiv_formulas_to_LaTeX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary packages"
      ],
      "metadata": {
        "id": "FLFSsm5LaOSW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XxqRRgJTdeX"
      },
      "outputs": [],
      "source": [
        "!pip install compress-pickle\n",
        "!pip install imagesize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load packages"
      ],
      "metadata": {
        "id": "TTRcK6E3aTWR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfyBCdSOU3nz"
      },
      "outputs": [],
      "source": [
        "# parse arxiv data into formulas -> images,\n",
        "# and fulltexts, and combine into one pickle-dataframe\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from bs4 import BeautifulSoup\n",
        "import imagesize\n",
        "\n",
        "\n",
        "import subprocess\n",
        "import platform\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "from compress_pickle import dump, load\n",
        "import zipfile\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import ast\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import display, Math\n",
        "import json\n",
        "import sys\n",
        "import base64\n",
        "import requests\n",
        "from shutil import copyfile\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "def unzip(source,target):\n",
        "  with zipfile.ZipFile(source, 'r') as zip_ref:\n",
        "    zip_ref.extractall(target)\n",
        "\n",
        "\n",
        "def rm_make(dir):\n",
        "  try:\n",
        "    shutil.rmtree(dir)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    !mkdir $dir\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8us2iP_aNzY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "ItFhCxNLacQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak71CRMnZB_0"
      },
      "outputs": [],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1pKVIs4nrQ4HHv-WYDsBpbrbOIzM1GiRT/view?usp=sharing -O 'already_parsed.zip'\n",
        "!unzip already_parsed.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAIUBUiyri7o"
      },
      "outputs": [],
      "source": [
        "def convert(file_path):\n",
        "    \"\"\" Calls mathpix API on a png-file, returns API-json\"\"\"\n",
        "    image_uri = \"data:image/gif;base64,\" + base64.b64encode(open(file_path, \"rb\").read()).decode()\n",
        "    \n",
        "    try:\n",
        "        image_uri = \"data:image/gif;base64,\" + base64.b64encode(open(file_path, \"rb\").read()).decode()\n",
        "    except:\n",
        "        return 'Error'\n",
        "    \n",
        "    r = requests.post(\"https://api.mathpix.com/v3/latex\",\n",
        "        data=json.dumps({'src': image_uri,\n",
        "                         'formats': ['latex_styled','latex_normal','text','latex_list','mathml','asciimath','wolfram'],\n",
        "                         'confidence_threshold' : 0,\n",
        "                         'ocr':[\"math\", \"text\"],\n",
        "                         'beam_size':5,\n",
        "                         'format_options': {\"latex_styled\": {\"transforms\": [\"rm_spaces\"]}},\n",
        "\n",
        "\n",
        "                         'skip_recrop': False\n",
        "                        }),\n",
        "        headers={\"app_id\": \"app_id\", # anonymized for review\n",
        "                 \"app_key\": \"app_key\",\n",
        "                 \"Content-type\": \"application/json\"})\n",
        "    try:\n",
        "        return json.loads(r.text)\n",
        "    except:\n",
        "        return 'Error'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5zGEsEirlmO"
      },
      "outputs": [],
      "source": [
        "full_data_biorxiv = load(\"drive/MyDrive/biorxiv_zips/biorxiv_mathpixed_zips/biorxiv_frame_up_to_13.bz\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"drive/MyDrive/biorxiv_zips/biorxiv_fulltext_zip_files/\"\n",
        "os.listdir(base_dir)"
      ],
      "metadata": {
        "id": "EZyejzEiGjQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_earlier = ['January_2019.zip',\n",
        " 'September_2019.zip',\n",
        " 'January_2020.zip',\n",
        " 'October_2019.zip',\n",
        " 'April_2019.zip',\n",
        " 'December_2019.zip',\n",
        " 'October_2020.zip',\n",
        " 'February_2020.zip',\n",
        " 'August_2019.zip',\n",
        " 'June_2019.zip',\n",
        " 'July_2019.zip',\n",
        " 'May_2019.zip',\n",
        " 'April_2020.zip',\n",
        " 'May_2020.zip',\n",
        " 'December_2020.zip']"
      ],
      "metadata": {
        "id": "klBOvvpyeRE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUJXNdTwtEjF"
      },
      "outputs": [],
      "source": [
        "this_batch = [x for x in os.listdir(base_dir) if x not in parsed_earlier] # because we had to split processing over several steps\n",
        "this_batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with_mathpix = full_data_biorxiv[full_data_biorxiv['filtered_formulas'] != 'no formulas']\n",
        "with_mathpix.iloc[np.where(np.array([len(x) for x in with_mathpix['mathpix_returns']]) > 0)]\n",
        "# with_mathpix\n",
        "# np.sum([len(x) for x in with_mathpix['mathpix_returns']])"
      ],
      "metadata": {
        "id": "c0GqdjFSGltZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OSxcblsU4wY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "full_data_biorxiv['formula_images'] = np.empty((len(full_data_biorxiv), 0)).tolist()\n",
        "full_data_biorxiv['image_sizes'] = np.empty((len(full_data_biorxiv), 0)).tolist()\n",
        "full_data_biorxiv['formula_images'] = full_data_biorxiv['formula_images'].astype('object')\n",
        "full_data_biorxiv['image_sizes'] = full_data_biorxiv['image_sizes'].astype('object')\n",
        "\n",
        "\n",
        "\n",
        "all_files_counter = 0\n",
        "\n",
        "no_formulas = 20\n",
        "for this_zip_index,this_zip in tqdm.tqdm_notebook(enumerate(this_batch)): # loop over zip files\n",
        "  rm_make('target')\n",
        "  unzip(base_dir + this_zip,'target')\n",
        "  for article in tqdm.tqdm_notebook(os.listdir('target')): # loop over directories in each batch\n",
        "    this_articles_formula_images = []\n",
        "    sizes = []\n",
        "    for this_file in os.listdir('target/'+article): # extract this articles id\n",
        "      if this_file.endswith(\".xml\"):\n",
        "        article_id = this_file.replace('.xml','')\n",
        "    w = np.where(full_data_biorxiv['small_id'] == article_id)[0]\n",
        "    if len(w) == 0: # check if there are formulas\n",
        "      pass\n",
        "    else:\n",
        "      if full_data_biorxiv.iloc[w[-1]]['already_processed']: \n",
        "        \n",
        "        #check whether we already parsed some of the formulas. If yes, integrate them into the dataset\n",
        "        already_converted_filenames = list(already_parsed_frame[already_parsed_frame['article_id_x']==article_id]['filenames'])\n",
        "        if len(already_converted_filenames) < no_formulas:\n",
        "          formulas_w = np.array(range(0,len(already_converted_filenames)))\n",
        "        else:\n",
        "          formulas_w = np.random.randint(0,len(already_converted_filenames),no_formulas)\n",
        "\n",
        "        filenames_to_use = [already_converted_filenames[x] for x in formulas_w]\n",
        "        article_tuples = []\n",
        "        article_latex = []\n",
        "        for this_formula_filename in filenames_to_use:\n",
        "          with open('biorxiv_tuples_batch/'+this_formula_filename, \"r\",encoding='utf-8') as text_file:\n",
        "            tuple_list = text_file.read()\n",
        "          article_tuples.append(ast.literal_eval(tuple_list))\n",
        "          with open('expanded_latex_formulas/'+this_formula_filename, \"r\",encoding='utf-8') as text_file:\n",
        "            formula = text_file.read()\n",
        "          article_latex.append(formula)\n",
        "        full_data_biorxiv.at[w[-1],'formula_images'] = filenames_to_use\n",
        "        full_data_biorxiv.at[w[-1],'formula_tuples'] = article_tuples\n",
        "        full_data_biorxiv.at[w[-1],'filtered_formulas'] = article_latex\n",
        "\n",
        "\n",
        "\n",
        "      else:\n",
        "\n",
        "        # if the formulas have not yet been converted, convert them using mathpix:\n",
        "        formula_gifs = []\n",
        "        for this_file in os.listdir('target/'+article):\n",
        "          if this_file.endswith(\".gif\"):\n",
        "            formula_gifs.append(this_file)\n",
        "        len_formulas = len(formula_gifs)\n",
        "\n",
        "        if len_formulas < no_formulas:\n",
        "          formulas_w = np.array(range(0,len_formulas))\n",
        "        else:\n",
        "          formulas_w = np.random.randint(0,len_formulas,no_formulas)\n",
        "\n",
        "        filenames_to_use = [formula_gifs[x] for x in formulas_w]\n",
        "\n",
        "        pngs = []\n",
        "        for this_file in filenames_to_use: # extract this articles id\n",
        "          size = imagesize.get('target/'+article+'/'+this_file)\n",
        "          if (size[0] > 200) and (size[0] < 800) and (size[1] < 100) and (size[1] > 40):\n",
        "            png_name = this_file.replace('.gif','.png')\n",
        "            im = Image.open('target/'+article+'/'+this_file)\n",
        "            im.save('target/'+article+'/'+png_name,'PNG')\n",
        "            pngs.append(png_name)\n",
        "\n",
        "        mathpix_returns = []\n",
        "        gathered_latex = []\n",
        "        for png_name in pngs:\n",
        "          returned_object = convert('target/'+article+'/'+png_name)\n",
        "          time.sleep(0.33)\n",
        "          mathpix_returns.append(returned_object)\n",
        "          try:\n",
        "            gathered_latex.append(returned_object['latex_styled'])\n",
        "          except KeyError:\n",
        "                print('parsing unsuccesful -error')\n",
        "          \n",
        "        \n",
        "        full_data_biorxiv.at[w[-1],'mathpix_returns'] = mathpix_returns\n",
        "        full_data_biorxiv.at[w[-1],'filtered_formulas'] = gathered_latex\n",
        "  dump(full_data_biorxiv, \"drive/MyDrive/biorxiv_zips/biorxiv_mathpixed_zips/biorxiv_frame_up_to_\"+str(this_zip_index+15)+ \".bz\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "converting_biorxiv_formulas_to_LaTeX.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}