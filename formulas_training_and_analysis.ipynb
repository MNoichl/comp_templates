{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MNoichl/tttms_public/blob/main/formulas_training_and_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary packages"
      ],
      "metadata": {
        "id": "XCVOwkmWXruu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1zp9z3MQjtH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install --upgrade gensim\n",
        "!pip install --upgrade umap-learn\n",
        "!pip install compress-pickle\n",
        "!pip install cylouvain\n",
        "!sudo apt-get install latexml\n",
        "!sudo apt-get install libtext-unidecode-perl \n",
        "!apt-get update\n",
        "!sudo apt-get install latexml\n",
        "!latexmlmath \\\\frac{-b\\\\pm\\\\sqrt{b^2-4ac}}{2a}\n",
        "!pip install hdbscan\n",
        "!pip install loess\n",
        "!pip install cmocean"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load packages"
      ],
      "metadata": {
        "id": "PoiuSY9eXv0j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-nJMZwBQjtQ"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import umap\n",
        "from scipy import stats\n",
        "\n",
        "import subprocess\n",
        "import platform\n",
        "import shutil\n",
        "\n",
        "from compress_pickle import dump, load\n",
        "import zipfile\n",
        "import cylouvain\n",
        "import networkx as nx\n",
        "\n",
        "from IPython.display import display, Math, Latex\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Tangent-functions"
      ],
      "metadata": {
        "id": "NMNOE_g5XzDB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBvzP-JOijBf"
      },
      "outputs": [],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1NSx7sQw8Kk1zQl5aaLWftj8T9SHvaeCC/view?usp=sharing -O \"TangentS.zip\"\n",
        "!unzip TangentS.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OAT0LMdhqN4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from xml.dom import minidom\n",
        "from io import StringIO\n",
        "from xml.dom.minidom import parseString\n",
        "\n",
        "\n",
        "from TangentS.math_tan.math_extractor import MathExtractor\n",
        "from TangentS.math_tan.symbol_tree import SymbolTree\n",
        "\n",
        "def convert_latex_formula_to_tuple_list(tex_query):\n",
        "    # print(\"Convert LaTeX to MathML:$\"+tex_query+\"$\",flush=True)\n",
        "    qvar_template_file = os.path.join(os.path.abspath(''), \"mws.sty.ltxml\")\n",
        "    if not os.path.exists(qvar_template_file):\n",
        "        print('Tried %s' % qvar_template_file, end=\": \")\n",
        "        sys.exit(\"Stylesheet for wildcard is missing\")\n",
        "\n",
        "    # Make sure there are no isolated % signs in tex_query (introduced by latexmlmath, for example, in 13C.mml test file) (FWT)\n",
        "    tex_query = re.sub(r'([^\\\\])%', r'\\1', tex_query)  # remove % not preceded by backslashes (FWT)\n",
        "    \n",
        "    with open('temporary_tex.tex', \"w\", encoding='utf-8') as text_file:\n",
        "        text_file.write('\\\\begin{equation} ' +tex_query + ' \\\\end{equation}')\n",
        "\n",
        "    cmd = 'timeout 5s latexml' + ' --preload=amsmath' + ' --preload=amsfonts' + ' --destination=temporary_xml.xml' +' temporary_tex.tex '+ ' --preload=mws.sty.ltxml'\n",
        "    !{cmd}\n",
        "    cmd = 'timeout 5s latexmlpost' + ' --contentmathml' + ' --destination=temporary_xml_2.xml' + ' temporary_xml.xml'\n",
        "    !{cmd}\n",
        "\n",
        "\n",
        "    xmldoc = minidom.parse('temporary_xml_2.xml')\n",
        "    equation_type_objects = []\n",
        "    paraNode = xmldoc.getElementsByTagName('para')[0]\n",
        "    for child in paraNode.childNodes:\n",
        "        if 'equation' in str(child):\n",
        "            equation_type_objects.append(child)\n",
        "\n",
        "    for i,this_equation_object in enumerate(equation_type_objects): \n",
        "        xml_formula_list = this_equation_object.getElementsByTagName('Math')\n",
        "        for j,this_xml_formula in enumerate(xml_formula_list):\n",
        "            this_xml_formula = this_xml_formula.firstChild\n",
        "\n",
        "\n",
        "            this_xml_formula.setAttribute(\"xmlns\", \"http://www.w3.org/1998/Math/MathML\")\n",
        "            out = StringIO()\n",
        "            this_xml_formula.writexml(out)\n",
        "            mathml = out.getvalue()\n",
        "            mathml = mathml.replace('m:','')\n",
        "            mathml = mathml.replace('<semantics>','').replace('<\\semantics>','')\n",
        "            mathml = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n\\n' + mathml\n",
        "            cmml = MathExtractor.isolate_cmml(mathml)\n",
        "            cmml = re.sub('<share href=\\\".*\\\"><\\/share>','',cmml)\n",
        "            current_tree = MathExtractor.convert_to_semanticsymbol(cmml)\n",
        "            temp = SymbolTree(current_tree)\n",
        "            tuple_list = temp.get_pairs(window=2, eob=True)\n",
        "\n",
        "    return tuple_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjxa6rEVTW_g"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregate data \n",
        "(unnecessary for re-runs: Just load data below)"
      ],
      "metadata": {
        "id": "edr9rgH2X3Pb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg_mkAUxUYd7"
      },
      "outputs": [],
      "source": [
        "from os.path import exists\n",
        "\n",
        "files_to_load = [\n",
        "                 (0,48000),\n",
        "                 (48000,50000),\n",
        "                 (50000,58000),\n",
        "  \t             (58000,74000),\n",
        "                 (74000,78000),\n",
        "                 (78000,84000),\n",
        "                 (84000,98000),\n",
        "                 (98000,100000),\n",
        "                 (100000,130000),\n",
        "                 (130000,134000),\n",
        "                 (134000,142000),\n",
        "                 (142000,150000),\n",
        "                 (150000,152000),\n",
        "                 (152000,158000),\n",
        "                 (158000,160000),\n",
        "                 (160000,162000),\n",
        "                 (162000,172000),\n",
        "                 (172000,176000),\n",
        "                 (176000,190000),\n",
        "                 (190000,196000),\n",
        "                 (194000,200000), \n",
        "                 (200000,202000),\n",
        "                 (202000,208000),\n",
        "                 (208000,220000),\n",
        "                 (220000,224000), \n",
        "                 (224000,226000),\n",
        "                 (226000,228000),\n",
        "                 (228000,230000),\n",
        "                 (230000,236000),\n",
        "                 (236000,240000),\n",
        "                 (240000,244000),\n",
        "                 (244000,246000),\n",
        "                 (246000,250000),\n",
        "                 (250000,258000),\n",
        "                 (258000,266000),\n",
        "                 (266000,270000),\n",
        "                 (270000,278000),\n",
        "                 (278000,280000),\n",
        "                 (280000,290000),\n",
        "                 (290000,300000),\n",
        "                 (300000,316000),\n",
        "                 (316000,326000),\n",
        "                 (326000,330000),\n",
        "                 (330000,336000),\n",
        "                 (336000,350000),\n",
        "                 (350000,370000),\n",
        "                 (370000,383960)\n",
        "                 ]\n",
        "\n",
        "for start, stop in tqdm.tqdm_notebook(files_to_load):\n",
        "  file_exists = exists(\"drive/MyDrive/combined_formula_parsing_results_v3/formula_tuple_list_\" + str(start) +\"_\"+ str(stop) + \".bz\")\n",
        "  print(file_exists)\n",
        "\n",
        "base_df = load(\"drive/MyDrive/combined_formula_parsing_results_v3/formula_tuple_list_\"+str(files_to_load[0][0])+\"_\"+str(files_to_load[0][1])+\".bz\")\n",
        "\n",
        "\n",
        "for start, stop in tqdm.tqdm_notebook(files_to_load[1:]):\n",
        "  this_df = load(\"drive/MyDrive/combined_formula_parsing_results_v3/formula_tuple_list_\" + str(start) +\"_\"+ str(stop) + \".bz\")\n",
        "  base_df[start:stop] = this_df[start:stop]\n",
        "  this_df = pd.DataFrame(this_df)\n",
        "  # this_df.columns = ['formula_tuples']\n",
        "  print(np.sum([len(x) for x in this_df['formula_tuples'] if x != 'no formulas']))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm85fKcqY3QM"
      },
      "outputs": [],
      "source": [
        "formula_df = pd.DataFrame(base_df)\n",
        "\n",
        "formula_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGmi7zPaRm_j"
      },
      "outputs": [],
      "source": [
        "full_data = load(\"drive/MyDrive/ARXIV_FORMULA_PARSING/full_data_rejoined_with_clusters.bz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOTmJcY7SbmT"
      },
      "outputs": [],
      "source": [
        "full_data[['filtered_formulas','formula_tuples','actually_transformed_formulas']] = formula_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8WSDyxYaHxK"
      },
      "outputs": [],
      "source": [
        "full_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dump(full_data, \"drive/MyDrive/ARXIV_FORMULA_PARSING/full_data_joined_with_formulas.bz\")"
      ],
      "metadata": {
        "id": "vK-B1OzYV4wc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset (start here for replicatory runs)"
      ],
      "metadata": {
        "id": "u8XehpkYXDL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1-5ZrFDj_6tff7tCRd8nqlVf6Ls-l8-x1/view?usp=sharing -O \"full_data_joined_with_formulas.bz\"\n",
        "full_data = load(\"full_data_joined_with_formulas.bz\")"
      ],
      "metadata": {
        "id": "gFIoTH7H8ThL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNeRPodUQjtc"
      },
      "outputs": [],
      "source": [
        "formula_collection = []\n",
        "for ix, row in tqdm.tqdm_notebook(full_data.iterrows()):\n",
        "  if row['actually_transformed_formulas'] == 'no formulas':\n",
        "    pass\n",
        "  else:\n",
        "    if len(row['actually_transformed_formulas']) == len(row['formula_tuples']):\n",
        "      usable_label = True\n",
        "    else:\n",
        "      usable_label = False\n",
        "    for formula, tuples in zip(row['actually_transformed_formulas'] ,row['formula_tuples'] ):\n",
        "      if len(tuples) > 1:\n",
        "        formula_collection.append({'formula':formula,\n",
        "                                  'tuples':tuples,\n",
        "                                  'cluster':row['cluster'],\n",
        "                                  'color':row['color'],\n",
        "                                  'id':row['id'],\n",
        "                                  'origin':row['origin'],\n",
        "                                   'usable_label': usable_label})\n",
        "    else:\n",
        "      pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb8cCDaVmd2O"
      },
      "outputs": [],
      "source": [
        "# Count available formulas:\n",
        "print('biorxiv: ',len([item for item in formula_collection if item['origin'] == 'biorxiv']))\n",
        "print('arxiv: ',len([item for item in formula_collection if item['origin'] == 'arxiv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2tiSl13QsjB"
      },
      "outputs": [],
      "source": [
        "formula_collection = [x for x in formula_collection if x['usable_label'] == True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGPLLx4TQjte"
      },
      "outputs": [],
      "source": [
        "flat_formula_tuples = [x['tuples'] for x in formula_collection] \n",
        "len(flat_formula_tuples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTS5REgsQjtx"
      },
      "source": [
        "# Training the model\n",
        "(uneccessary for re-runs, we can load the pretrained one below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LimlOgz0Qjt2"
      },
      "outputs": [],
      "source": [
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "class EpochLogger(CallbackAny2Vec):\n",
        "    '''Callback to log information about training'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_begin(self, model):\n",
        "        print(\"Epoch #{} start\".format(self.epoch))\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        model.save(r'drive/MyDrive/formulaFT_models/combined_equation_fasttext_model_v02_'+str(self.epoch)+'.model')\n",
        "        print(\"Epoch #{} end\".format(self.epoch))\n",
        "        self.epoch += 1\n",
        "        \n",
        "epoch_logger = EpochLogger()  \n",
        "        \n",
        "from gensim.models import FastText\n",
        "my_tokens = flat_formula_tuples\n",
        "print('tokens retrieved')\n",
        "model = FastText(vector_size=300, window=13, sg=1,\n",
        "                 hs=1,workers=8, negative=15,\n",
        "                 min_n=5, max_n=40, #word_ngrams=3,\n",
        "                 min_count=7)\n",
        "\n",
        "\n",
        "model.build_vocab(my_tokens) \n",
        "print('voc built, training')\n",
        "\n",
        "model.train(my_tokens,total_examples=model.corpus_count,epochs =9, callbacks=[epoch_logger])\n",
        "print('training complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sBTJiZNfQjt3"
      },
      "outputs": [],
      "source": [
        "# Saving the model after training:\n",
        "# model.save(r'drive/MyDrive/formulaFT_models/combined_equation_fasttext_model_v01.model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the pretrained model"
      ],
      "metadata": {
        "id": "TR8B-MiOaotS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1-yzwqBBsCh9FQIs6iBmUYh0M0xWhAFLS/view?usp=sharing -O \"combined_equation_fasttext_model_v02_6.model\"\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1-vkI7clJx62w2GIuiVj6Ia9c7mFYnhYh/view?usp=sharing -O \"combined_equation_fasttext_model_v02_6.model.wv.vectors_vocab.npy\"\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1-x4htbDWiN3gDb_WpSMFfrJ99QvycHiD/view?usp=sharing -O 'combined_equation_fasttext_model_v02_6.model.wv.vectors_ngrams.npy'\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1-xLAmr4WvvH10MpRQwd_5JH0TvIv-Xls/view?usp=sharing -O 'combined_equation_fasttext_model_v02_6.model.syn1.npy'\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1-yf6oFOqpKfTpsyAsQeXMYl3Ri464vK4/view?usp=sharing -O 'combined_equation_fasttext_model_v02_6.model.syn1neg.npy'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FVdDplBa72Q",
        "outputId": "22fe5f6e-2ef0-4c1e-99ea-4dd60cebe7f0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-yzwqBBsCh9FQIs6iBmUYh0M0xWhAFLS\n",
            "To: /content/combined_equation_fasttext_model_v02_6.model\n",
            "100% 149M/149M [00:00<00:00, 241MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-vkI7clJx62w2GIuiVj6Ia9c7mFYnhYh\n",
            "To: /content/combined_equation_fasttext_model_v02_6.model.wv.vectors_vocab.npy\n",
            "100% 1.00G/1.00G [00:03<00:00, 256MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-x4htbDWiN3gDb_WpSMFfrJ99QvycHiD\n",
            "To: /content/combined_equation_fasttext_model_v02_6.model.wv.vectors_ngrams.npy\n",
            "100% 2.40G/2.40G [00:10<00:00, 221MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-xLAmr4WvvH10MpRQwd_5JH0TvIv-Xls\n",
            "To: /content/combined_equation_fasttext_model_v02_6.model.syn1.npy\n",
            "100% 1.00G/1.00G [00:05<00:00, 169MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-yf6oFOqpKfTpsyAsQeXMYl3Ri464vK4\n",
            "To: /content/combined_equation_fasttext_model_v02_6.model.syn1neg.npy\n",
            "100% 1.00G/1.00G [00:11<00:00, 88.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZDREmh0bQjt5"
      },
      "outputs": [],
      "source": [
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "from gensim.models import FastText\n",
        "\n",
        "class EpochLogger(CallbackAny2Vec):\n",
        "    '''Callback to log information about training'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_begin(self, model):\n",
        "        print(\"Epoch #{} start\".format(self.epoch))\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        print(\"Epoch #{} end\".format(self.epoch))\n",
        "        self.epoch += 1\n",
        "\n",
        "epoch_logger = EpochLogger()  \n",
        "        \n",
        "model = FastText.load(r'combined_equation_fasttext_model_v02_6.model')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Draw a random subsample"
      ],
      "metadata": {
        "id": "ygRsnGM4jGdW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvNpuciWQjt5"
      },
      "outputs": [],
      "source": [
        "w_rand = np.random.randint(0,len(flat_formula_tuples),500000)\n",
        "flat_formula_tuples_small = [flat_formula_tuples[x] for x in w_rand]\n",
        "w_in_collection = [formula_collection[x] for x in w_rand] # select data for random sample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert tuples to vectors"
      ],
      "metadata": {
        "id": "_NEfN7B70OlH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bllPt4xfQjt6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from scipy.linalg import norm\n",
        "from scipy.stats import gmean\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "import functools\n",
        "from multiprocessing.dummy import Pool  # This is a thread-based Pool\n",
        "from multiprocessing import cpu_count\n",
        "import time\n",
        "         \n",
        "            \n",
        "def get_mean_vectors(model,x):\n",
        "    vectors = []\n",
        "    for y in x:\n",
        "        try: \n",
        "            vector = model.wv[y]\n",
        "            vectors.append(vector / np.linalg.norm(vector))\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    return np.mean(np.array(vectors),axis=0) #powermean(np.array(vectors), 2, axis = 0)\n",
        "\n",
        "pool = Pool(8)\n",
        "formula_vectors = list(tqdm.tqdm_notebook(pool.imap(functools.partial(get_mean_vectors, model), flat_formula_tuples_small)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqszW8KfQjt7"
      },
      "outputs": [],
      "source": [
        "embeddings = np.vstack(formula_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute layout"
      ],
      "metadata": {
        "id": "PvAE-aY__Up7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxrS0qKTQjuB"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "SVD = TruncatedSVD(n_components= 150, n_iter=7, random_state=42)\n",
        "XSVD = SVD.fit_transform(embeddings)\n",
        "print(XSVD.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVwWTcuRQjuC"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "\n",
        "umapped_equations_full = umap.UMAP(densmap=False,random_state=42,\n",
        "                    n_components=2,\n",
        "                    n_neighbors=10,\n",
        "                    min_dist=0.1,\n",
        "                    init=XSVD[:,0:2],\n",
        "                    metric='cosine',#n_epochs=200,#disconnection_distance =0.3,\n",
        "                    verbose=True,\n",
        "                    low_memory=True)\n",
        "\n",
        "umapped_equations_full.fit(XSVD)#[:,1:])#[:,1:])#\n",
        "umapped_equations = umapped_equations_full.embedding_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB_F8kvaQjuD"
      },
      "outputs": [],
      "source": [
        "sns.set(font=\"STIXGeneral\",font_scale=2.1)\n",
        "sns.set_style(\"white\")\n",
        "fig, ax = plt.subplots(figsize=(30,20))\n",
        "\n",
        "hfont = {'fontname':'STIXGeneral'}\n",
        "\n",
        "\n",
        "plt.scatter(umapped_equations[:, 0], umapped_equations[:, 1], s=0.6\n",
        "            , c=[x['color'] for x in w_in_collection],alpha=0.9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugbjcOYgWLgG"
      },
      "source": [
        "# Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dClUstsgrTg"
      },
      "outputs": [],
      "source": [
        "import hdbscan\n",
        "clusterer = hdbscan.HDBSCAN(min_cluster_size=40,\n",
        "                            min_samples=50, prediction_data=False).fit(umapped_equations)\n",
        "print(len(set(clusterer.labels_)))\n",
        "clustering_solution = clusterer.labels_\n",
        "# soft_clusters = hdbscan.all_points_membership_vectors(clusterer)\n",
        "# print(soft_clusters.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iJnOBbQnscE"
      },
      "outputs": [],
      "source": [
        "sns.set(font=\"STIXGeneral\",font_scale=2.1)\n",
        "sns.set_style(\"white\")\n",
        "fig, ax = plt.subplots(figsize=(30,20))\n",
        "\n",
        "hfont = {'fontname':'STIXGeneral'}\n",
        "\n",
        "\n",
        "clustered = (clustering_solution >= 0)\n",
        "plt.scatter(umapped_equations[~clustered, 0],\n",
        "            umapped_equations[~clustered, 1],\n",
        "            color=(0.5, 0.5, 0.5),\n",
        "            s=0.1,\n",
        "            alpha=0.5)\n",
        "plt.scatter(umapped_equations[clustered, 0],\n",
        "            umapped_equations[clustered, 1],\n",
        "            c=clustering_solution[clustered],\n",
        "            s=0.1,\n",
        "            cmap='Spectral');\n",
        "\n",
        "plt.axis('equal')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build nearest neighbours graph of formulas"
      ],
      "metadata": {
        "id": "T0AHq6Aqr5iC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJDZr_c3m1KA"
      },
      "outputs": [],
      "source": [
        "# %%timeit\n",
        "import pynndescent\n",
        "index = pynndescent.NNDescent(embeddings,#embeddings\n",
        "                              metric=\"cosine\",n_neighbors=90)\n",
        "index.prepare()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgYq7obIodn9"
      },
      "source": [
        "# Calculate textual distances to formulas' nearest neighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-_eUVQ8ovmw"
      },
      "outputs": [],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/12FKOy0jN9n1AJnSV-JeJlu1yw-1C39Q2/view?usp=sharing -O \"thematic_SVD_vectors.bz\"\n",
        "\n",
        "thematic_SVD = load(\"thematic_SVD_vectors.bz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVvmMWIuoupF"
      },
      "outputs": [],
      "source": [
        "accurate_neighbors = index.query(embeddings,\n",
        "                                 epsilon=0.2,k =40) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZHzqKYOouiU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "n_neighbors_to_consider = 5\n",
        "average_thematic_dists = []\n",
        "null_model = []\n",
        "\n",
        "for ix, these_neighbours in tqdm.tqdm_notebook(enumerate(accurate_neighbors[0])):\n",
        "\n",
        "  id_s = [w_in_collection[x]['id'] for x  in these_neighbours]\n",
        "  w_id_source = np.where(full_data['id'].isin([w_in_collection[ix]['id']]))[0]\n",
        "  id_s = [x for x in sorted(set(id_s), key=id_s.index)][1:n_neighbors_to_consider+1]\n",
        "  w_ids_targets = np.where(full_data['id'].isin(id_s))[0]\n",
        "  \n",
        "  dists = pairwise_distances(thematic_SVD[w_id_source,:], thematic_SVD[w_ids_targets,:], metric='cosine')\n",
        "  average_thematic_dists.append(np.mean(dists))\n",
        "\n",
        "  dists = pairwise_distances(thematic_SVD[w_id_source,:], thematic_SVD[np.random.randint(0,len(thematic_SVD),n_neighbors_to_consider),:], metric='cosine')\n",
        "  null_model.append(np.mean(dists))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmx6SCcCmvAj"
      },
      "source": [
        "# Plot Similarities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxAV5kd1mpEv"
      },
      "outputs": [],
      "source": [
        "sns.set(font_scale=.5)\n",
        "sns.set_style(\"ticks\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "sns.distplot(average_thematic_dists,color='#cc4157',hist=True, kde_kws={\"lw\": 3},)\n",
        "sns.distplot(null_model,color='#b3c3b9',hist=True, kde_kws={'color':'#686868',\"lw\": 3},)\n",
        "plt.xticks([np.round(x,decimals=2) for x in np.linspace(0,1,51)],)\n",
        "\n",
        "plt.savefig('dist_comp_random_matter_10_with_hist.png', dpi=300)\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "stats.ttest_ind(average_thematic_dists, null_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0uQSUkdeJYH"
      },
      "outputs": [],
      "source": [
        "treated_part_cl_sol = clustering_solution[0:len(average_thematic_dists)]\n",
        "mean_average_dist_by_cluster = np.zeros(len(treated_part_cl_sol))\n",
        "for small_clust in tqdm.tqdm_notebook(np.unique(treated_part_cl_sol)):\n",
        "    where_small_clust = np.where(np.array(treated_part_cl_sol)==small_clust)[0]\n",
        "    mean_average_dist_by_cluster[where_small_clust]= np.mean([average_thematic_dists[x]for x in where_small_clust])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5x5PoWqTPhx"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cmocean\n",
        "\n",
        "sns.set(font=\"STIXGeneral\",font_scale=2.1)\n",
        "sns.set_style(\"white\")\n",
        "fig, ax = plt.subplots(figsize=(30,20))\n",
        "\n",
        "\n",
        "clustered = (treated_part_cl_sol >= 0)\n",
        "\n",
        "hfont = {'fontname':'STIXGeneral'}\n",
        "\n",
        "\n",
        "plt.scatter(umapped_equations[0:len(average_thematic_dists), 0][~clustered],\n",
        "            umapped_equations[0:len(average_thematic_dists), 1][~clustered],\n",
        "            color=(0.5, 0.5, 0.5),\n",
        "            s=0.1,\n",
        "            alpha=0.3)\n",
        "\n",
        "\n",
        "plt.scatter(umapped_equations[0:len(average_thematic_dists), 0][clustered],\n",
        "            umapped_equations[0:len(average_thematic_dists), 1][clustered],\n",
        "            c= np.array(mean_average_dist_by_cluster)[clustered],#average_thematic_dists ,#[average_thematic_dists[x] for x in np.argsort(average_thematic_dists)],#[np.log(x) for x in average_thematic_dists],\n",
        "            s=1,alpha=.3,\n",
        "            cmap=cmocean.cm.matter_r,\n",
        "            vmin=np.percentile(mean_average_dist_by_cluster, 1),\n",
        "            vmax=np.percentile(mean_average_dist_by_cluster, 99)\n",
        "            )\n",
        "cbar = plt.colorbar()\n",
        "cbar.set_alpha(1)\n",
        "cbar.draw_all()\n",
        "plt.axis('equal')\n",
        "\n",
        "plt.savefig('clustering_with_distances_matter.png', dpi=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdWKsdmIAWMG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get formulas closest to clusters' centroids, for labeling"
      ],
      "metadata": {
        "id": "GHTNXARCsoRo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgu3PPlcLFw_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "cluster_centers = []\n",
        "for small_clust in tqdm.tqdm_notebook(np.unique(clustering_solution)):\n",
        "    where_small_clust = np.where(np.array(clustering_solution)==small_clust)[0]\n",
        "    cluster_centers.append(np.median(embeddings[where_small_clust,:],axis=0))\n",
        "cluster_centers = np.array(cluster_centers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueM0sdEDeigB"
      },
      "outputs": [],
      "source": [
        "# plot cluster-positions\n",
        "sns.set(font=\"STIXGeneral\",font_scale=.4\n",
        "        )\n",
        "sns.set_style(\"white\")\n",
        "fig, ax = plt.subplots(figsize=(30,20))\n",
        "\n",
        "hfont = {'fontname':'STIXGeneral'}\n",
        "\n",
        "plt.scatter(umapped_equations[0:len(average_thematic_dists), 0][~clustered],\n",
        "            umapped_equations[0:len(average_thematic_dists), 1][~clustered],\n",
        "            color=(0.5, 0.5, 0.5),\n",
        "            s=0.1,\n",
        "            alpha=0.5)\n",
        "\n",
        "\n",
        "plt.scatter(umapped_equations[0:len(average_thematic_dists), 0][clustered],\n",
        "            umapped_equations[0:len(average_thematic_dists), 1][clustered],\n",
        "            c= np.array(mean_average_dist_by_cluster)[clustered],#average_thematic_dists ,#[average_thematic_dists[x] for x in np.argsort(average_thematic_dists)],#[np.log(x) for x in average_thematic_dists],\n",
        "            s=1,alpha=1,\n",
        "            cmap=cmocean.cm.haline,\n",
        "            vmin=np.percentile(mean_average_dist_by_cluster, 1),\n",
        "            vmax=np.percentile(mean_average_dist_by_cluster, 99)\n",
        "            )\n",
        "plt.colorbar()\n",
        "\n",
        "for ix,small_clust in tqdm.tqdm_notebook(enumerate(np.unique(clustering_solution))):\n",
        "    where_small_clust = np.where(np.array(clustering_solution)==small_clust)[0]\n",
        "    center = np.median(umapped_equations[where_small_clust,:],axis=0)\n",
        "    # print(center[0])\n",
        "\n",
        "    plt.text(x=center[0],\n",
        "          y=center[1],\n",
        "          s=str(ix), horizontalalignment='center',\n",
        "     verticalalignment='center')\n",
        "  \n",
        "plt.axis('equal')\n",
        "plt.savefig('clustering_with_labels.png', dpi=300)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare relative cluster-membership-graphics"
      ],
      "metadata": {
        "id": "gpPbCXCVtBIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIBrg1BOZ6aq"
      },
      "outputs": [],
      "source": [
        "c = Counter([x['cluster'] for x in w_in_collection])\n",
        "c_zero = Counter({x:0 for x in c})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXlDrIjWeT-s"
      },
      "outputs": [],
      "source": [
        "text_clusters = list(dict(Counter([x['cluster'] for x in w_in_collection])).keys())\n",
        "text_colors = list(dict(Counter([x['color'] for x in w_in_collection])).keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T_5WBx2hOGm"
      },
      "outputs": [],
      "source": [
        "palette = dict(zip(text_clusters,text_colors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqs6BBVhVdvW"
      },
      "outputs": [],
      "source": [
        "cluster_composition_count_frames = []\n",
        "for ix,small_clust in tqdm.tqdm_notebook(enumerate(np.unique(clustering_solution))):\n",
        "    where_small_clust = np.where(np.array(clustering_solution)==small_clust)[0]\n",
        "    present_text_clusters = [w_in_collection[x]['cluster'] for x in where_small_clust]\n",
        "    this_counter = c_zero.copy()\n",
        "    this_counter.update(present_text_clusters)\n",
        "    for key in this_counter:\n",
        "\n",
        "      this_counter[key]  = this_counter[key] / c[key]\n",
        "    count_frame = pd.DataFrame(dict(this_counter), index=[0]).T\n",
        "    count_frame = count_frame.reset_index()\n",
        "    count_frame.columns = ['cluster','counts']\n",
        "    count_frame['x'] = 1\n",
        "    count_frame['cluster'] = pd.Categorical(count_frame['cluster'],[-1,10, 1,  3, 4,2,0,5,  6, 7,11,16, 17,20, 8, 9, \n",
        "                                                                     19,12, 13,  15, \n",
        "                                                                       21, 14,22,18,23]) #reorder, to better fit the visual order of the textual UMAP\n",
        "\n",
        "    cluster_composition_count_frames.append(count_frame)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print out full report on the formula-clustering"
      ],
      "metadata": {
        "id": "7xcch0jKtUJA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xkk4IA3NHMP"
      },
      "outputs": [],
      "source": [
        "neighbors = index.query(cluster_centers, epsilon=0.2, k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ApukCfkO7ds"
      },
      "outputs": [],
      "source": [
        "for cluster, cluster_center_nn in enumerate(neighbors[0]):\n",
        "  print('Cluster: ', cluster)\n",
        "  for ix in cluster_center_nn[0:10]:\n",
        "    formula = w_in_collection[ix]['formula'].replace(r'\\begin{equation}','').replace(r'\\end{equation}','')\n",
        "    formula = '$' + formula.replace(r'\\begin{eqnarray}','').replace(r'\\end{eqnarray}','')+'$'\n",
        "    formula = re.sub(\n",
        "            r\"\\\\label{.*?}\", \n",
        "            '', \n",
        "            formula)\n",
        "\n",
        "    display(Math(formula))\n",
        "    print(formula)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(6,1))\n",
        "  ax = sns.histplot(cluster_composition_count_frames[cluster], y='x', hue='cluster', weights='counts',\n",
        "            multiple='stack', palette=palette, shrink=4)\n",
        "  plt.legend([],[], frameon=False)\n",
        "  ax.axis('off')\n",
        "  plt.show()\n",
        "  print('\\n\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model by querying for the normal-distribution-formula\n"
      ],
      "metadata": {
        "id": "Wk0OH1NOtc66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC_JzIM-Y1No"
      },
      "outputs": [],
      "source": [
        "\n",
        "query = r\"f(x)={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {x-\\mu }{\\sigma }}\\right)^{2}\"\n",
        "display(Math(query))\n",
        "\n",
        "\n",
        "\n",
        "print('Turning query into tuples.')\n",
        "query_tuples = convert_latex_formula_to_tuple_list(query)\n",
        "\n",
        "print('Encoding tupels.')\n",
        "encoded_query = get_mean_vectors(model,query_tuples) \n",
        "\n",
        "print('Searching closest matches...')\n",
        "neighbors = index.query(encoded_query.reshape(1,-1), epsilon=0.9,k=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiZx9Yo_Y1RX"
      },
      "outputs": [],
      "source": [
        "for ix, this_neighbor in enumerate(neighbors[0][0][0:30]):\n",
        "  print(np.round(neighbors[1][0][ix],decimals = 3))\n",
        "  formula =  w_in_collection[this_neighbor]['formula']\n",
        "  formula = formula.replace(r'\\begin{equation}','').replace(r'\\end{equation}','')\n",
        "  formula = re.sub(\n",
        "          r\"\\\\label{.*?}\", \n",
        "          '', \n",
        "          formula)\n",
        "  display(Math('$'+formula+'$'))\n",
        "  print(len(w_in_collection[this_neighbor]['tuples']))\n",
        "  print(w_in_collection[this_neighbor]['tuples']) # look at embeddings!\n",
        "  print(w_in_collection[this_neighbor]['formula'])\n",
        "\n",
        "  print('\\n')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "edr9rgH2X3Pb",
        "MTS5REgsQjtx"
      ],
      "machine_shape": "hm",
      "name": "formulas_training_and _analysis",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}