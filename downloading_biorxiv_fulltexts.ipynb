{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MNoichl/tttms_public/blob/main/downloading_biorxiv_fulltexts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary packages"
      ],
      "metadata": {
        "id": "rqnZibyy2eRA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFdVtV00S90N"
      },
      "outputs": [],
      "source": [
        "!pip install xmltodict\n",
        "!pip install flatten_dict\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load packages and link google drive"
      ],
      "metadata": {
        "id": "dFVI_fnB2kS3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgUnfmQDmk2Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import json\n",
        "\n",
        "import re\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import tarfile\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from shutil import copyfile, copy, copy2\n",
        "import shutil\n",
        "import xmltodict\n",
        "\n",
        "import gzip\n",
        "import zipfile\n",
        "import boto3, configparser\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXCrhsK_cD91"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R5HOJHC5BEs"
      },
      "source": [
        "# Download BioRxiv-fulltext and images from Amazon-Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hs-UGkuIq-A"
      },
      "outputs": [],
      "source": [
        "def rm_make(dir):\n",
        "  try:\n",
        "    shutil.rmtree(dir)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    !mkdir $dir\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "def unzip(source,target):\n",
        "  with zipfile.ZipFile(source, 'r') as zip_ref:\n",
        "    zip_ref.extractall(target)\n",
        "\n",
        "\n",
        "\n",
        "def return_dir_paths(path):\n",
        "  all_files = []\n",
        "  for path, subdirs, files in os.walk(path):\n",
        "      for name in files:\n",
        "          all_files.append(os.path.join(path, name))\n",
        "  return all_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWKSmvDJO6ZP"
      },
      "outputs": [],
      "source": [
        "!rm -rf config.ini\n",
        "# censored for review before publication\n",
        "\n",
        "with open('config.ini', 'w') as f:\n",
        "    f.write(\"\"\"[DEFAULT]\n",
        "ACCESS_KEY = ACCESS_KEY\n",
        "SECRET_KEY =SECRET_KEY\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WpmRnMAO52F"
      },
      "outputs": [],
      "source": [
        "import calendar\n",
        "\n",
        "query_months = []\n",
        "for year in [2019,2020]:\n",
        "  for month in list(calendar.month_name)[1:]:  \n",
        "    query_months.append(month+ '_' + str(year))\n",
        "print(query_months)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy3tSgSSO6Vo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9ODEg9xcQkzJ"
      },
      "outputs": [],
      "source": [
        "configs = configparser.SafeConfigParser()\n",
        "configs.read('config.ini')\n",
        "\n",
        "\n",
        "bucket_name = 'biorxiv-src-monthly'\n",
        "# _PREFIX = 'Current_Content/July_2020'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "client = boto3.client('s3', aws_access_key_id=configs['DEFAULT']['ACCESS_KEY'],\n",
        "                            aws_secret_access_key=configs['DEFAULT']['SECRET_KEY'],\n",
        "                      )\n",
        "\n",
        "\n",
        "for this_month in query_months:\n",
        "\n",
        "  rm_make('big_temp')\n",
        "  prefix = 'Current_Content/' + this_month\n",
        "\n",
        "  paginator = client.get_paginator('list_objects_v2')\n",
        "  pages = paginator.paginate(Bucket=bucket_name,RequestPayer='requester', Prefix=prefix)\n",
        "\n",
        "  this_months_objects = []\n",
        "  for page in pages:\n",
        "      for obj in page['Contents']:\n",
        "        this_months_objects.append(obj['Key'])\n",
        "  for this_object in tqdm.tqdm_notebook(this_months_objects):\n",
        "\n",
        "\n",
        "\n",
        "    if this_object[-4:] == 'meca':\n",
        "      rm_make('temp_zip')\n",
        "      file_id = this_object.split('/')[-1]\n",
        "      \n",
        "      client.download_file(\n",
        "        Bucket=bucket_name,\n",
        "        Key=this_object,  # name of key to download from\n",
        "        Filename='temp_zip/'+file_id,  # path to file to download to\n",
        "        ExtraArgs={\"RequestPayer\": \"requester\"},\n",
        "      )\n",
        "      rm_make('temp')\n",
        "      unzip('temp_zip/'+file_id, 'temp')\n",
        "\n",
        "      preprint_folder = 'big_temp/'+file_id.replace('.meca','')\n",
        "      rm_make(preprint_folder)\n",
        "      for this_file in return_dir_paths('temp/content'):\n",
        "        if ('eqn' in this_file) or (this_file[-3:] == 'xml'):\n",
        "          shutil.copy(this_file, preprint_folder+'/'+this_file.split('/')[-1])\n",
        "\n",
        "  shutil.make_archive(\"drive/MyDrive/biorxiv_fulltext_zip_files/\"+this_month, 'zip', 'big_temp')\n",
        "\n",
        "\n",
        "    \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81ahjql4JE9c"
      },
      "outputs": [],
      "source": [
        "this_months_objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5x6ylT8JFAY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwXlUpTfJFDq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJoQ0wzoJFHQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuYHiR12JFR9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiV0_skTJFXD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFVvv035JFdW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szMa_cjM62Bu"
      },
      "source": [
        "The following code is adapted/taken from a tutorial by Brienna Herold, https://towardsdatascience.com/how-to-bulk-access-arxiv-full-text-preprints-58026e19e8ef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXVNCD4EO6ct"
      },
      "outputs": [],
      "source": [
        "import boto3, configparser\n",
        "\n",
        "s3resource = None\n",
        "\n",
        "def setup():\n",
        "    \"\"\"Creates S3 resource & sets configs to enable download.\"\"\"\n",
        "\n",
        "    print('Connecting to Amazon S3...')\n",
        "\n",
        "    # Securely import configs from private config file\n",
        "    configs = configparser.SafeConfigParser()\n",
        "    configs.read('config.ini')\n",
        "\n",
        "    # Create S3 resource & set configs\n",
        "    global s3resource\n",
        "    s3resource = boto3.resource(\n",
        "        's3',  # the AWS resource we want to use\n",
        "        aws_access_key_id=configs['DEFAULT']['ACCESS_KEY'],\n",
        "        aws_secret_access_key=configs['DEFAULT']['SECRET_KEY'],\n",
        "        region_name='us-east-1'  # same region arxiv bucket is in\n",
        "    )\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \"\"\"Runs if script is called on command line\"\"\"\n",
        "\n",
        "    # Create S3 resource & set configs\n",
        "    setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCLgQ_k1ZzKQ"
      },
      "outputs": [],
      "source": [
        "configs = configparser.SafeConfigParser()\n",
        "configs.read('config.ini')\n",
        "\n",
        "\n",
        "my_bucket = s3resource.Bucket('biorxiv-src-monthly')\n",
        "_BUCKET_NAME = 'biorxiv-src-monthly'\n",
        "_PREFIX = 'Current_Content/July_2020'\n",
        "\n",
        "client = boto3.client('s3', aws_access_key_id=configs['DEFAULT']['ACCESS_KEY'],\n",
        "                            aws_secret_access_key=configs['DEFAULT']['SECRET_KEY'],\n",
        "                      )\n",
        "\n",
        "# def ListFiles(client):\n",
        "#     \"\"\"List files in specific S3 URL\"\"\"\n",
        "#     response = client.list_objects(Bucket=_BUCKET_NAME,RequestPayer='requester', Prefix=_PREFIX)\n",
        "#     print(response)\n",
        "#     for content in response.get('Contents', []):\n",
        "#         yield content.get('Key')\n",
        "\n",
        "# file_list = ListFiles(client)\n",
        "# for file in file_list:\n",
        "#     print('File found: %s' % file)\n",
        "\n",
        "\n",
        "response = client.list_objects(Bucket=_BUCKET_NAME,RequestPayer='requester', Prefix=_PREFIX)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIrP1MbDttE7"
      },
      "outputs": [],
      "source": [
        "\n",
        "paginator = client.get_paginator('list_objects_v2')\n",
        "pages = paginator.paginate(Bucket=_BUCKET_NAME,RequestPayer='requester', Prefix=_PREFIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4DWCv2Fws_Z"
      },
      "outputs": [],
      "source": [
        "for page in pages:\n",
        "    # for obj in page['Contents']:\n",
        "    print(page['Contents'])\n",
        "        # print(obj['Size'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWfbho3rqVEY"
      },
      "outputs": [],
      "source": [
        "test_key = 'Current_Content/July_2020/'#340fc728-6cb4-1014-83f1-fe3fe01219f7.meca'\n",
        "\n",
        "client.download_file(\n",
        "  Bucket=_BUCKET_NAME,\n",
        "  Key=test_key,  # name of key to download from\n",
        "  Filename='test.meca',  # path to file to download to\n",
        "  ExtraArgs={\"RequestPayer\": \"requester\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtdtfCmeqUh8"
      },
      "outputs": [],
      "source": [
        "!unzip test.meca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQm_DdMDO6gT"
      },
      "outputs": [],
      "source": [
        "yimport boto3, configparser, os, botocore\n",
        "\n",
        "def download_file(key):\n",
        "    \"\"\"\n",
        "    Downloads given filename from source bucket to destination directory.\n",
        "    Parameters\n",
        "    ----------\n",
        "    key : str\n",
        "        Name of file to download\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure src directory exists \n",
        "    if not os.path.isdir('src'):\n",
        "        os.makedirs('src')\n",
        "\n",
        "    # Download file\n",
        "    print('\\nDownloading s3://arxiv/{} to {}...'.format(key, key))\n",
        "\n",
        "    try:\n",
        "        s3resource.meta.client.download_file(\n",
        "            Bucket='arxiv', \n",
        "            Key=key,  # name of file to download from\n",
        "            Filename=key,  # path to file to download to\n",
        "            ExtraArgs={'RequestPayer':'requester'})\n",
        "    except botocore.exceptions.ClientError as e:\n",
        "        if e.response['Error']['Code'] == \"404\":\n",
        "            print('ERROR: ' + key + \" does not exist in arxiv bucket\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \"\"\"Runs if script is called on command line\"\"\"\n",
        "\n",
        "    # Download manifest file to current directory\n",
        "    download_file('src/arXiv_src_manifest.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ebJD8W1SlUu"
      },
      "outputs": [],
      "source": [
        "with open('src/arXiv_src_manifest.xml', 'r') as file:\n",
        "    data = file.read()\n",
        "xml_content = xmltodict.parse(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqwzEt4RO6jq"
      },
      "outputs": [],
      "source": [
        "manifest_frame = pd.DataFrame(xml_content['arXivSRC']['file'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cfs9-5rUBfv"
      },
      "outputs": [],
      "source": [
        "def rm_make(dir):\n",
        "  try:\n",
        "    shutil.rmtree(dir)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    !mkdir $dir\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "def return_dir_paths(path):\n",
        "  all_files = []\n",
        "  for path, subdirs, files in os.walk(path):\n",
        "      for name in files:\n",
        "          all_files.append(os.path.join(path, name))\n",
        "  return all_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZP0C4KNXlYo"
      },
      "outputs": [],
      "source": [
        "output_directory = 'drive/MyDrive/arxiv_2019_2022_tex_collection_fourth_run'\n",
        "# rm_make(output_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkOcMpKvkcko"
      },
      "outputs": [],
      "source": [
        "all_query_codes = []\n",
        "for year in tqdm.tqdm_notebook(selected_years):\n",
        "  for month in tqdm.tqdm_notebook(range(1,13)):\n",
        "    all_query_codes.append(year[-2:]+str(month).zfill(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXL9PilwkoGI"
      },
      "outputs": [],
      "source": [
        "# all_query_codes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDGybEbWO6nX"
      },
      "outputs": [],
      "source": [
        "for query_code in ['2012']: # all_query_codes[3:]:\n",
        "  print('Downloading code: ', query_code)\n",
        "  this_years_queries = manifest_frame[manifest_frame[\"yymm\"] == query_code]\n",
        "  for ix, row in tqdm.tqdm_notebook(this_years_queries.iterrows()):\n",
        "    key = row[\"filename\"]\n",
        "    print('    Downloading file: ', key)\n",
        "    try:\n",
        "      rm_make(\"src\")\n",
        "      s3resource.meta.client.download_file(\n",
        "        Bucket=\"arxiv\",\n",
        "        Key=key,  # name of key to download from\n",
        "        Filename=key,  # path to file to download to\n",
        "        ExtraArgs={\"RequestPayer\": \"requester\"},\n",
        "      )\n",
        "\n",
        "      # extract the whole package to temporary directory\n",
        "      rm_make(\"temporary_files\")\n",
        "      rm_make(\"temporary_files_extracted\")\n",
        "      tar = tarfile.open(key, \"r:\")\n",
        "      tar.extractall(path=\"temporary_files\")\n",
        "      tar.close()\n",
        "\n",
        "      # loop over all extracted files, copying the .tex files to our output directory, into their own folder named after their arxiv id\n",
        "      all_files = return_dir_paths(\"temporary_files\")\n",
        "      print('    Extracting file: ', key)\n",
        "      for this_file in tqdm.tqdm_notebook(all_files):\n",
        "        this_file_path = this_file.split(\"/\")[-1].replace(\".gz\", \"\")\n",
        "        try:\n",
        "          if this_file[-2:] == \"gz\":\n",
        "            tar = tarfile.open(this_file)\n",
        "            tar.extractall(\n",
        "              path=\"temporary_files_extracted/\" + this_file_path\n",
        "            )\n",
        "            tar.close()\n",
        "            for extracted_file in return_dir_paths(\n",
        "              \"temporary_files_extracted/\" + this_file_path\n",
        "            ):\n",
        "              if extracted_file.endswith(\".tex\"):\n",
        "                try:\n",
        "                  copy(\n",
        "                    extracted_file,\n",
        "                    output_directory\n",
        "                    + \"/\"\n",
        "                    + this_file_path\n",
        "                    + \"/\"\n",
        "                    + extracted_file.split(\"/\")[-1],\n",
        "                  )\n",
        "                except IOError as io_err:\n",
        "                  os.makedirs(output_directory + \"/\" + this_file_path)\n",
        "                  copy(\n",
        "                    extracted_file,\n",
        "                    output_directory\n",
        "                    + \"/\"\n",
        "                    + this_file_path\n",
        "                    + \"/\"\n",
        "                    + extracted_file.split(\"/\")[-1],\n",
        "                  )\n",
        "\n",
        "        except (KeyboardInterrupt, SystemExit):\n",
        "          print(\"program stopped manually\")\n",
        "          raise\n",
        "        except:\n",
        "          # print('file')\n",
        "          pass\n",
        "\n",
        "    except botocore.exceptions.ClientError as e:\n",
        "      if e.response[\"Error\"][\"Code\"] == \"404\":\n",
        "        print(\"ERROR: \" + key + \" does not exist in arxiv bucket\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzybvfV74bpa"
      },
      "outputs": [],
      "source": [
        "# /content/drive/MyDrive/arxiv_2019_2022_tex_collection_fourth_run\n",
        "\n",
        "\n",
        "\n",
        "import shutil\n",
        "shutil.make_archive('drive/MyDrive/arxiv_2019_2022_tex_collection_fourth_run.zip', 'zip', 'drive/MyDrive/arxiv_2019_2022_tex_collection_fourth_run')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRdBeyEQ78vJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWSQOM4R78jm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDR7bJTs78Zk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDAEHIZQ78On"
      },
      "outputs": [],
      "source": [
        "this_file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g781Gah78C3"
      },
      "outputs": [],
      "source": [
        "extracted_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKGlDweH771-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQc9nNDJ76xE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKcuejlk76kh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHUuuH1DO6q8"
      },
      "outputs": [],
      "source": [
        "# plt.scatter([float(x[0:4]) for x in manifest_frame.yymm],\n",
        "#          [float(x) for x in manifest_frame['size']])\n",
        "# manifest_frame[manifest_frame['yymm'] == '1901']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrFMPBvbVAPF"
      },
      "outputs": [],
      "source": [
        "# [float(x[0:4]) for x in manifest_frame.timestamp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASu6tNuEO6uq"
      },
      "outputs": [],
      "source": [
        "# paginator = s3resource.meta.client.get_paginator('list_objects_v2')\n",
        "\n",
        "# page_iterator = paginator.paginate(\n",
        "#   Bucket='arxiv',\n",
        "#   RequestPayer='requester',\n",
        "#   Prefix='src/'\n",
        "# )\n",
        "\n",
        "# for page in page_iterator:\n",
        "#   for x in page['Contents']:\n",
        "#     print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8mjX0PWO61q"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of downloading_biorxiv_fulltexts.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}